{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from natsort import natsorted\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "import visualkeras\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages(folder):\n",
    "    files = os.listdir(folder)\n",
    "    images = []\n",
    "    p = os.path.join(folder)\n",
    "    D = natsorted(os.listdir(p))\n",
    "    names = [f for f in D if not f.startswith('.')]\n",
    "    for img in names:\n",
    "        im = cv2.imread(os.path.join(p, img), cv2.IMREAD_GRAYSCALE)\n",
    "        images.append(im)\n",
    "    return images\n",
    "\n",
    "path = '/Users/alexandrasmith/Desktop/Honours Project/Databases/Phase2/'\n",
    "\n",
    "flair = getImages(path + 'Flair')\n",
    "t1 = getImages(path + 'T1')\n",
    "t1ce = getImages(path + 'T1ce')\n",
    "t2 = getImages(path + 'T2')\n",
    "seg = getImages(path + 'Segmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(modality, patch_size, number_of_ims, num_strides):\n",
    "    '''Create data sets used for training\n",
    "    Returns:    array of image patches\n",
    "                image (pixel) labels'''\n",
    "    idx = np.int(np.floor(patch_size/2))\n",
    "    # strides = 1 -> 42436 patches per image (VALID padding)\n",
    "    # strides = 2 -> 10609 patches per image\n",
    "    # stides = 3 -> 4761 patches per image\n",
    "    # stides = 4 -> 2704 patches per image\n",
    "    # shape of matrix of total patches = [number_of_images_used*number_patches_per_image, 35, 35]\n",
    "    all_patches = np.zeros(((number_of_ims*900), 35, 35, 1))\n",
    "    all_patches_labels = np.zeros((number_of_ims*900, 35, 35, 1))\n",
    "    for i in range(number_of_ims):\n",
    "        F = np.reshape(modality[i], (1, 240, 240, 1))\n",
    "        S = np.reshape(seg[i], (1, 240, 240, 1))\n",
    "        P = tf.image.extract_patches(images=F, sizes=[1, patch_size, patch_size, 1], strides=[1, num_strides, num_strides, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "        P_seg = tf.image.extract_patches(images=S, sizes=[1, patch_size, patch_size, 1], strides=[1, num_strides, num_strides, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "        p = P.numpy(); p_seg = P_seg.numpy()\n",
    "        sh = p.shape; num_patches = np.int((sh[1]**2))\n",
    "        # print(num_patches)\n",
    "        # get numpy array of size (number_patches, patch_size, patch_size)\n",
    "        patches = np.reshape(p, (num_patches, patch_size, patch_size, 1)); y_patches = np.reshape(p_seg, (num_patches, patch_size, patch_size, 1))\n",
    "        for k in range(num_patches):\n",
    "            all_patches[k, :, :] = patches[k, :, :]\n",
    "            all_patches_labels[k, :, :] = y_patches[k, :, :]\n",
    "\n",
    "    # get pixel labels for centre pixel of each patch: label 0 or 1 corresponding to two class labels\n",
    "    # 0 == healthy/background and 1 == tumorous\n",
    "    all_pix_labels = []\n",
    "    for patch in all_patches_labels:\n",
    "        i = patch[idx][idx]\n",
    "        if i == 255:\n",
    "            all_pix_labels.append(1)\n",
    "        else:\n",
    "            all_pix_labels.append(0)\n",
    "    return all_patches, all_pix_labels\n",
    "\n",
    "def train(X_train, y_train, X_val, y_val):\n",
    "    ''' Configure and train CNN'''\n",
    "    model = models.Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding = 'same', input_shape=(35, 35, 1)),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        # Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "        # MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=128, activation='relu'), # fully connected layer\n",
    "        Dropout(0.5),\n",
    "        # Flatten(),\n",
    "        Dense(units=2, activation='softmax'), # output layer\n",
    "    ])\n",
    "\n",
    "    # model = models.Sequential([\n",
    "    # Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(35, 35, 4),padding='same'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # MaxPool2D((2, 2),padding='same'),\n",
    "    # Conv2D(64, (3, 3), activation='linear',padding='same'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # MaxPool2D(pool_size=(2, 2),padding='same'),\n",
    "    # Conv2D(64, (3, 3), activation='linear',padding='same'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # MaxPool2D(pool_size=(2, 2),padding='same'),\n",
    "    # Flatten(),\n",
    "    # Dense(128, activation='linear'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # Dense(2, activation='softmax'),\n",
    "    # ])\n",
    "\n",
    "    # display model architecture\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, np.array(y_train), batch_size=64, epochs=10, validation_data=(X_val, np.array(y_val)), shuffle=True)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def evaluate_model(model, history, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    # plot loss during training\n",
    "    plt.subplot(211)\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], 'm--', label='validation')\n",
    "    plt.legend()\n",
    "    # plot accuracy during training\n",
    "    plt.subplot(212)\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], 'm--', label='validation')\n",
    "    plt.legend()\n",
    "    return loss, accuracy\n",
    "\n",
    "from sklearn import metrics as m\n",
    "\n",
    "def get_measures(true_labels, pred_labels):\n",
    "    # calculate other statistical measures\n",
    "    cm = m.confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "    tp = cm[1][1]; tn = cm[0][0]; fp = cm[0][1]; fn = cm[1][0]\n",
    "    conf_accuracy = (float (tp+tn) / float(tp + tn + fp + fn)) # calculate accuracy\n",
    "    conf_misclassification = 1 - conf_accuracy # calculate mis-classification\n",
    "    conf_sensitivity = (tp / float(tp + fn)) # calculate the sensitivity\n",
    "    conf_specificity = (tn / float(tn + fp)) # calculate the specificity\n",
    "    conf_precision = (tp / float(tp + fp)) # calculate precision\n",
    "    dsc = (2*tp) / (fp + 2*tp + fn) # calculate dice similarity coefficient\n",
    "\n",
    "    # print(f'Accuracy: {round(conf_accuracy,2)}') \n",
    "    # print(f'Mis-Classification: {round(conf_misclassification,2)}') \n",
    "    # print(f'Sensitivity: {round(conf_sensitivity,2)}') \n",
    "    # print(f'Specificity: {round(conf_specificity,2)}') \n",
    "    # print(f'Precision: {round(conf_precision,2)}')\n",
    "    # print(f'DSC: {round(dsc,2)}')\n",
    "    print('Accuracy: {}'.format(conf_accuracy))\n",
    "    print('Mis-Classification: {}'.format(conf_misclassification))\n",
    "    print('Sensitivity: {}'.format(conf_sensitivity))\n",
    "    print('Specificity: {}'.format(conf_specificity))\n",
    "    print('Precision: {}'.format(conf_precision))\n",
    "    print('DSC: {}'.format(dsc))\n",
    "\n",
    "    return conf_accuracy\n",
    "\n",
    "def acc(model, X_test, y_test, thresh):\n",
    "    '''Manually calculate accuracy for patches \n",
    "    and given pixel classes'''\n",
    "    # checking accuracy manually\n",
    "    pred_prob = model.predict(X_test)\n",
    "    # apply threshold\n",
    "    T = np.where(pred_prob < thresh, 0, pred_prob)\n",
    "    pred_labels = np.argmax(T, axis=-1)\n",
    "    # convert tensor test labels into vector\n",
    "    y_labels = []\n",
    "    for i in range(len(pred_labels)):\n",
    "        m = y_test[i]\n",
    "        if m[0] == 1:\n",
    "            y_labels.append(0)\n",
    "        elif m[1] == 1:\n",
    "            y_labels.append(1)\n",
    "    count = 0\n",
    "    for i in range(len(pred_labels)):\n",
    "        if pred_labels[i] == y_labels[i]:\n",
    "            count += 1\n",
    "    per = count/len(pred_labels)\n",
    "    acc = get_measures(y_labels, pred_labels)\n",
    "    return per\n",
    "\n",
    "def seg_image(model, modality, seg, patch_size, im_num, thresh):\n",
    "    '''Predict labels and segment for one given image'''\n",
    "    idx = np.int(np.floor(patch_size/2))\n",
    "    test_ = np.reshape(modality[im_num], (1, 240, 240, 1)); seg_ = np.reshape(seg[im_num], (1, 240, 240, 1))\n",
    "    # extract image patches\n",
    "    P_test = tf.image.extract_patches(images=test_, sizes=[1, patch_size, patch_size, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "    P_seg_test = tf.image.extract_patches(images=seg_, sizes=[1, patch_size, patch_size, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "    # convert to numpy array\n",
    "    p_test = P_test.numpy(); p_seg_test = P_seg_test.numpy()\n",
    "    # reshape(number_patches, patch_size, patch_size)\n",
    "    test_patches = np.reshape(p_test, (57600, patch_size, patch_size, 1)); test_y_patches = np.reshape(p_seg_test, (57600, patch_size, patch_size, 1))\n",
    "    test_pix = []\n",
    "    for patch in test_y_patches:\n",
    "        i = patch[idx][idx]\n",
    "        if i == 255:\n",
    "            test_pix.append(1)\n",
    "        else:\n",
    "            test_pix.append(0)\n",
    "\n",
    "    # normalise and one-hot encoding\n",
    "    test_patches = test_patches/255; test_patches = np.reshape(test_patches, (test_patches.shape[0], test_patches.shape[1], test_patches.shape[2], 1))\n",
    "    test_pix_oh = tf.one_hot(test_pix, depth=2)\n",
    "\n",
    "    Loss, Acc = model.evaluate(test_patches, test_pix_oh)\n",
    "    labels_ = model.predict(test_patches)\n",
    "    # apply threshold for pixel to be classified as tumorous\n",
    "    T = np.where(labels_ < thresh, 0, labels_)\n",
    "    ll = np.argmax(T, axis=-1) \n",
    "    test_seg_image = np.reshape(ll, (240, 240))\n",
    "    acc = get_measures(test_pix, ll)\n",
    "    # print(f'Loss: {round(Loss,2)}')\n",
    "    print('Loss: {}'.format(Loss))\n",
    "    # plot segmentation result (if one image given)\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # plt.subplot(131); plt.imshow(modality[im_num], cmap=\"gray\"); plt.axis('off'); plt.title(\"Original \" + str(modality))\n",
    "    # plt.subplot(132); plt.imshow(seg[im_num], cmap=\"gray\"); plt.axis('off'); plt.title(\"Original segmented\")\n",
    "    # plt.subplot(133); plt.imshow(test_seg_image, cmap=\"gray\"); plt.axis('off'); plt.title(\"Predicted. Accuracy: \" + str(acc) + \". Threshold: \" + str(thresh))\n",
    "    # plt.tight_layout(); plt.show()\n",
    "\n",
    "    return test_seg_image\n",
    "\n",
    "def data_k_fold(X, y, k, test_indices, other_indices):\n",
    "    # run model on for one fold\n",
    "    # access indices for this fold\n",
    "    test_i = test_indices[k-1]; other_i = other_indices[k-1]\n",
    "    # get data sets\n",
    "    # testing\n",
    "    X_test = np.zeros(((len(test_i)), 35, 35, 4))\n",
    "    for i in range(len(test_i)):\n",
    "        ind = test_i[i]\n",
    "        X_test[i, :, :, :] = X[ind, :, :, :]\n",
    "    y_test = np.take(y, test_i)\n",
    "    X_other = np.zeros(((len(other_i)), 35, 35, 4))\n",
    "    for i in range(len(other_i)):\n",
    "        ind = other_i[i]\n",
    "        X_other[i, :, :, :] = X[ind, :, :, :]\n",
    "    y_other = np.take(y, other_i)\n",
    "\n",
    "    # split remaning into optimisation and training sets\n",
    "    X_o, X_val, y_o, y_val = train_test_split(X_other, y_other, test_size=0.3333, random_state=0)\n",
    "    X_train, X_opt, y_train, y_opt = train_test_split(X_o, y_o, test_size=0.3333, random_state=0)\n",
    "    # normalizing the pixel values and reshape data\n",
    "    X_train = X_train/255; X_test = X_test/255; X_opt = X_opt/255\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 4))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], X_val.shape[2], 4))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 4))\n",
    "    X_opt = np.reshape(X_opt, (X_opt.shape[0], X_opt.shape[1], X_opt.shape[2], 4))\n",
    "    # one hot encoding\n",
    "    y_train = tf.one_hot(y_train, depth=2); y_val = tf.one_hot(y_val, depth=2); y_test = tf.one_hot(y_test, depth=2); y_opt = tf.one_hot(y_opt, depth=2)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_opt, y_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360000, 35, 35, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare patches\n",
    "X, y = get_data(modality=flair, patch_size=35, number_of_ims=400, num_strides=7)\n",
    "print(X.shape)\n",
    "# use K fold cross validation\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "all_fold_test_indices = []; all_fold_other_indices = [] # store so that can run separately\n",
    "for train_index, test_index in kf.split(X):\n",
    "    all_fold_other_indices.append(train_index)\n",
    "    all_fold_test_indices.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Kernel is dead",
     "output_type": "error",
     "traceback": [
      "Error: Kernel is dead",
      "at g._sendKernelShellControl (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006305)",
      "at g.sendShellMessage (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1006074)",
      "at g.requestExecute (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:1008616)",
      "at d.requestExecute (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:37:328037)",
      "at S.requestExecute (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:32:19306)",
      "at w.executeCodeCell (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300924)",
      "at w.execute (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/alexandrasmith/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "# train: 80%, test: 10%, optimisation: 20%\n",
    "k = 1\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_opt, y_opt = data_k_fold(X, y, k, all_fold_test_indices, all_fold_other_indices)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_opt.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit CNN model\n",
    "model, history = train(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal threshold\n",
    "ts = np.linspace(0.5, 1, 100)\n",
    "opt_thresh = 0\n",
    "bst_thresh = 0.5\n",
    "for thresh in ts:\n",
    "    p = acc(model, X_opt, y_opt, thresh)\n",
    "    if p > opt_thresh:\n",
    "        opt_thresh = p\n",
    "        bst_thresh = thresh\n",
    "print(\"Optimal threshold: {} achieving accuracy of: {}\".format(opt_thresh, bst_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance\n",
    "loss, accuracy = evaluate_model(model, history, X_test, y_test)\n",
    "print(\"\\nModel's Evaluation Metrics: \")\n",
    "print(\"---------------------------\")\n",
    "print(\"Accuracy: {} \\nLoss: {}\".format(accuracy, loss))\n",
    "# Predict accuracy manually\n",
    "perc = acc(model, X_test, y_test, 0.9)\n",
    "print(\"Accuracy: {}\".format(perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seg_image = seg_image(model, modality=flair, seg=seg, patch_size=35, im_num=281, thresh=0.5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
