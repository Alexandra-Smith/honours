{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from natsort import natsorted\n",
    "from matplotlib import pyplot as plt\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "import visualkeras\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages(folder):\n",
    "    files = os.listdir(folder)\n",
    "    images = []\n",
    "    p = os.path.join(folder)\n",
    "    D = natsorted(os.listdir(p))\n",
    "    names = [f for f in D if not f.startswith('.')]\n",
    "    for img in names:\n",
    "        im = cv2.imread(os.path.join(p, img), cv2.IMREAD_GRAYSCALE)\n",
    "        images.append(im)\n",
    "    return images\n",
    "\n",
    "path = '/Users/alexandrasmith/Desktop/Honours Project/Databases/Phase2/'\n",
    "\n",
    "flair = getImages(path + 'Flair')\n",
    "t1 = getImages(path + 'T1')\n",
    "t1ce = getImages(path + 'T1ce')\n",
    "t2 = getImages(path + 'T2')\n",
    "seg = getImages(path + 'Segmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating array of all modalities\n",
    "total = len(seg)\n",
    "# X is a 1499x240x240x4 array - training data containing all modalities\n",
    "X4 = np.zeros((total, 240, 240, 4))\n",
    "for i in range(total):\n",
    "    img1 = flair[i]; img2 = t1[i]; img3 = t1ce[i]; img4 = t2[i]\n",
    "    X4[i, :, :, 0] = img1; X4[i, :, :, 1] = img2; X4[i, :, :, 2] = img3; X4[i, :, :, 3] = img4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data sets used for training (using ALL modalities together)\n",
    "\n",
    "def get_data(X, patch_size, number_of_ims, num_strides):\n",
    "    '''Create data sets used for training\n",
    "    Returns:    array of image patches\n",
    "                image (pixel) labels'''\n",
    "    idx = np.int(np.floor(patch_size/2))\n",
    "    # strides = 1 -> 42436 patches per image (VALID padding)\n",
    "    # strides = 2 -> 10609 patches per image\n",
    "    # stides = 3 -> 4761 patches per image\n",
    "    # stides = 4 -> 2704 patches per image\n",
    "    # shape of matrix of total patches = [number_of_images_used*number_patches_per_image, 35, 35]\n",
    "    all_patches = np.zeros(((number_of_ims*1225), 35, 35, 4))\n",
    "    all_patches_labels = np.zeros((number_of_ims*1225, 35, 35, 1))\n",
    "    for i in range(number_of_ims):\n",
    "        F = np.reshape(X[i], (1, 240, 240, 4))\n",
    "        S = np.reshape(seg[i], (1, 240, 240, 1))\n",
    "        P = tf.image.extract_patches(images=F, sizes=[1, patch_size, patch_size, 1], strides=[1, num_strides, num_strides, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "        P_seg = tf.image.extract_patches(images=S, sizes=[1, patch_size, patch_size, 1], strides=[1, num_strides, num_strides, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "        p = P.numpy(); p_seg = P_seg.numpy()\n",
    "        sh = p.shape; num_patches = np.int((sh[1]**2))\n",
    "        # print(num_patches)\n",
    "        # get numpy array of size (number_patches, patch_size, patch_size)\n",
    "        patches = np.reshape(p, (num_patches, patch_size, patch_size, 4)); y_patches = np.reshape(p_seg, (num_patches, patch_size, patch_size, 1))\n",
    "        for k in range(num_patches):\n",
    "            all_patches[k, :, :] = patches[k, :, :]\n",
    "            all_patches_labels[k, :, :] = y_patches[k, :, :]\n",
    "\n",
    "    # get pixel labels for centre pixel of each patch: label 0 or 1 corresponding to two class labels\n",
    "    # 0 == healthy/background and 1 == tumorous\n",
    "    all_pix_labels = []\n",
    "    for patch in all_patches_labels:\n",
    "        i = patch[idx][idx]\n",
    "        if i == 255:\n",
    "            all_pix_labels.append(1)\n",
    "        else:\n",
    "            all_pix_labels.append(0)\n",
    "    return all_patches, all_pix_labels\n",
    "\n",
    "def split(X, y):\n",
    "    ''' Split all patches into training and\n",
    "    test data, normalise and one hot encoding done to\n",
    "    ensure data in correct format for training CNN.'''\n",
    "    # split into training and test (20%) sets\n",
    "    X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    # get validation data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_t, y_t, test_size=0.125, random_state=0)\n",
    "    # normalizing the pixel values and reshape data\n",
    "    X_train = X_train/255; X_test = X_test/255; X_val = X_val/255\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 4))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 4))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], X_val.shape[2], 4))\n",
    "    # one hot encoding\n",
    "    y_train = tf.one_hot(y_train, depth=2); y_test = tf.one_hot(y_test, depth=2); y_val = tf.one_hot(y_val, depth=2)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def train(X_train, y_train, X_val, y_val):\n",
    "    ''' Configure and train CNN'''\n",
    "    model = models.Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding = 'same', input_shape=(35, 35, 4)),\n",
    "        # MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=128, activation='relu'), # fully connected layer\n",
    "        Dropout(0.5),\n",
    "        # Flatten(),\n",
    "        Dense(units=2, activation='softmax'), # output layer\n",
    "    ])\n",
    "    # model = models.Sequential([\n",
    "    # Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(35, 35, 4),padding='same'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # MaxPool2D((2, 2),padding='same'),\n",
    "    # Conv2D(64, (3, 3), activation='linear',padding='same'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # MaxPool2D(pool_size=(2, 2),padding='same'),\n",
    "    # Conv2D(128, (3, 3), activation='linear',padding='same'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # MaxPool2D(pool_size=(2, 2),padding='same'),\n",
    "    # Flatten(),\n",
    "    # Dense(128, activation='linear'),\n",
    "    # LeakyReLU(alpha=0.1),\n",
    "    # Dense(2, activation='softmax'),\n",
    "    # ])\n",
    "\n",
    "    # display model architecture\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, np.array(y_train), batch_size=64, epochs=15, validation_data=(X_val, np.array(y_val)), shuffle=True)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def evaluate_model(model, history, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    # plot loss during training\n",
    "    plt.subplot(211)\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], 'm--', label='validation')\n",
    "    plt.legend()\n",
    "    # plot accuracy during training\n",
    "    plt.subplot(212)\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], 'm--', label='validation')\n",
    "    plt.legend()\n",
    "    return loss, accuracy\n",
    "\n",
    "from sklearn import metrics as m\n",
    "\n",
    "def get_measures(true_labels, pred_labels):\n",
    "    # calculate other statistical measures\n",
    "    cm = m.confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "    tp = cm[1][1]; tn = cm[0][0]; fp = cm[0][1]; fn = cm[1][0]\n",
    "    conf_accuracy = (float (tp+tn) / float(tp + tn + fp + fn)) # calculate accuracy\n",
    "    conf_misclassification = 1 - conf_accuracy # calculate mis-classification\n",
    "    conf_sensitivity = (tp / float(tp + fn)) # calculate the sensitivity\n",
    "    conf_specificity = (tn / float(tn + fp)) # calculate the specificity\n",
    "    conf_precision = (tp / float(tp + fp)) # calculate precision\n",
    "    dsc = (2*tp) / (fp + 2*tp + fn) # calculate dice similarity coefficient\n",
    "\n",
    "    print(f'Accuracy: {round(conf_accuracy,2)}') \n",
    "    print(f'Mis-Classification: {round(conf_misclassification,2)}') \n",
    "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \n",
    "    print(f'Specificity: {round(conf_specificity,2)}') \n",
    "    print(f'Precision: {round(conf_precision,2)}')\n",
    "    print(f'DSC: {round(dsc,2)}')\n",
    "\n",
    "    return conf_accuracy\n",
    "\n",
    "def acc(model, X_test, y_test, thresh):\n",
    "    '''Manually calculate accuracy for patches \n",
    "    and given pixel classes'''\n",
    "    # checking accuracy manually\n",
    "    pred_prob = model.predict(X_test)\n",
    "    # apply threshold\n",
    "    T = np.where(pred_prob < thresh, 0, pred_prob)\n",
    "    pred_labels = np.argmax(T, axis=-1)\n",
    "    # convert tensor test labels into vector\n",
    "    y_labels = []\n",
    "    for i in range(len(pred_labels)):\n",
    "        m = y_test[i]\n",
    "        if m[0] == 1:\n",
    "            y_labels.append(0)\n",
    "        elif m[1] == 1:\n",
    "            y_labels.append(1)\n",
    "    count = 0\n",
    "    for i in range(len(pred_labels)):\n",
    "        if pred_labels[i] == y_labels[i]:\n",
    "            count += 1\n",
    "    per = count/len(pred_labels)\n",
    "    acc = get_measures(y_labels, pred_labels)\n",
    "    return per\n",
    "\n",
    "def seg_image(model, X, seg, patch_size, im_num, thresh):\n",
    "    '''Predict labels and segment for one given image'''\n",
    "    idx = np.int(np.floor(patch_size/2))\n",
    "    test_ = np.reshape(X4[im_num], (1, 240, 240, 4)); seg_ = np.reshape(seg[im_num], (1, 240, 240, 1))\n",
    "    # extract image patches\n",
    "    P_test = tf.image.extract_patches(images=test_, sizes=[1, patch_size, patch_size, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "    P_seg_test = tf.image.extract_patches(images=seg_, sizes=[1, patch_size, patch_size, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='SAME')\n",
    "    # convert to numpy array\n",
    "    p_test = P_test.numpy(); p_seg_test = P_seg_test.numpy()\n",
    "    # reshape(number_patches, patch_size, patch_size)\n",
    "    test_patches = np.reshape(p_test, (57600, patch_size, patch_size, 4)); test_y_patches = np.reshape(p_seg_test, (57600, patch_size, patch_size, 1))\n",
    "    test_pix = []\n",
    "    for patch in test_y_patches:\n",
    "        i = patch[idx][idx]\n",
    "        if i == 255:\n",
    "            test_pix.append(1)\n",
    "        else:\n",
    "            test_pix.append(0)\n",
    "\n",
    "    # normalise and one-hot encoding\n",
    "    test_patches = test_patches/255; test_patches = np.reshape(test_patches, (test_patches.shape[0], test_patches.shape[1], test_patches.shape[2], 1))\n",
    "    test_pix_oh = tf.one_hot(test_pix, depth=2)\n",
    "\n",
    "    Loss, Acc = model.evaluate(test_patches, test_pix_oh)\n",
    "    labels_ = model.predict(test_patches)\n",
    "    # apply threshold for pixel to be classified as tumorous\n",
    "    T = np.where(labels_ < thresh, 0, labels_)\n",
    "    ll = np.argmax(T, axis=-1) \n",
    "    test_seg_image = np.reshape(ll, (240, 240))\n",
    "    acc = get_measures(test_pix, ll)\n",
    "    print(f'Loss: {round(Loss,2)}')\n",
    "    # plot segmentation result (if one image given)\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # plt.subplot(131); plt.imshow(X4[im_num, :, :, 0], cmap=\"gray\"); plt.axis('off'); plt.title(\"Original flair image\")\n",
    "    # plt.subplot(132); plt.imshow(seg[im_num], cmap=\"gray\"); plt.axis('off'); plt.title(\"Ground truth\")\n",
    "    # plt.subplot(133); plt.imshow(test_seg_image, cmap=\"gray\"); plt.axis('off'); plt.title(\"Predicted. Accuracy: \" + str(acc) + \". Threshold: \" + str(thresh))\n",
    "    # plt.tight_layout(); plt.show()\n",
    "\n",
    "    return test_seg_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare patches\n",
    "X, y = get_data(X4, patch_size=35, number_of_ims=10, num_strides=6) # strides = 6 -> 1225 patches used per training image\n",
    "print(X[0].shape)\n",
    "# split data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit CNN model\n",
    "model, history = train(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance\n",
    "loss, accuracy = evaluate_model(model, history, X_test, y_test)\n",
    "print(\"\\nModel's Evaluation Metrics: \")\n",
    "print(\"---------------------------\")\n",
    "print(\"Accuracy: {} \\nLoss: {}\".format(accuracy, loss))\n",
    "\n",
    "# Predicrt accuracy manually\n",
    "perc = acc(model, X_test, y_test, 0.5)\n",
    "print(\"Accuracy: {}\".format(perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seg_image = seg_image(model, X4, seg, patch_size=35, im_num=281, thresh=0.5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
